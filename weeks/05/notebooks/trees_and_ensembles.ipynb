{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5bc626-bb53-4cab-a7ff-0c6acdc28fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75fb9f-86f6-4162-889c-5423a712fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d9ab0-c960-403e-8083-9210c23470c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc2d85-da7f-437a-a1b5-a71361932f98",
   "metadata": {},
   "source": [
    "# Airline Passenger Satisfaction\n",
    "\n",
    "From last week, we can look at the dataset corresponding to predicting whether passengers were satisfied with the airline. We read in both a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb137bc-c469-458d-a097-4bc998899748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../04/data/airline_satisfaction/train.csv\", index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a04a81-44dd-4488-9a69-0a95a4ebd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../../04/data/airline_satisfaction/test.csv\", index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0f996-20a8-4914-8e84-c8f81cb79ef4",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "\n",
    "To start, we train a logistic regression model using only numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e46202-771f-4a44-9744-c2c82e7a976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple model using only numerical features\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c70cc-3980-4132-b717-52ea02d78372",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_features = [\"id\"]\n",
    "features = [\n",
    "    column\n",
    "    for column, series in train.items()\n",
    "    if np.issubdtype(series.dtype, np.number) and column not in ignore_features\n",
    "]\n",
    "target = \"satisfaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914930db-a822-4332-82dd-67e49868ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca85c5d-8d1a-4fec-8a98-b9960825f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[features]\n",
    "y_test = label_encoder.transform(test[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e315d5d-60b0-403f-b499-255a748ecadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        (\"estimator\", LogisticRegression(random_state=RANDOM_SEED)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c0ede-ecc8-4ce4-9961-955e0d167309",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310e3a4-3039-41e8-b21b-0deff8d78a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7cec44-4447-433a-a960-2ecb002005d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdb474-e275-4256-85b6-5799198dd010",
   "metadata": {},
   "source": [
    "Let's look at the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a31593-84bf-4177-9f72-c6487967b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Training\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c71bd1-0143-4e8a-a639-b386ad1555be",
   "metadata": {},
   "source": [
    "Model has decent performance, no real signs of overfitting.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Now, let's try out a random forest on the data using the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af9540-54a3-40d0-8239-f9091e827237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9428fc6-9a05-4300-861c-b63db6d4dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        # NOTE: We do not have to scale our data\n",
    "        (\"estimator\", RandomForestClassifier(random_state=RANDOM_SEED)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2057b2e-5ee6-424b-b352-68dac4761072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba53aa4-5678-4c93-96a1-8078fa9c4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24547ee-5f5a-42ba-b2a0-b3c8028d9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951174d8-4488-4aaa-9082-956019cbd106",
   "metadata": {},
   "source": [
    "Wow! It's definitely overfit to the training data, but it performs quite well on the test data. Let's see what's going on inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501cdcff-b7cf-430f-ab58-500bc0d17dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.named_steps[\"estimator\"]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09591bbf-9f3f-4161-99bb-327ee36c8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model (hyper)parameters\")\n",
    "print(f\"{'n_estimators':25s} = {model.n_estimators}\")\n",
    "for param in model.estimator_params:\n",
    "    print(f\"{param:25s} = {getattr(model, param)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4cbb9-4661-46d3-8c57-3309bcc26bdf",
   "metadata": {},
   "source": [
    "The random forest is made up of 100 individual decision trees. Here's the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dfa3b2-ceff-4b3a-bb79-8611cfdab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.estimators_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494b153-ca53-42e9-a4f9-101210a75d35",
   "metadata": {},
   "source": [
    "And here are some details about that tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d9f53-eb13-460d-ba6d-ac51f646e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f33af-d20b-4fb9-bbbd-b9e8d36f892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in (\"max_depth\", \"n_leaves\", \"node_count\"):\n",
    "    print(f\"{param:25s} = {getattr(tree.tree_, param):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397387e3-b68e-497a-bf8d-03caabd7a79f",
   "metadata": {},
   "source": [
    "Lastly, let's see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5b58e-2d8d-4046-8733-deb773325680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    tree,\n",
    "    out_file=None,\n",
    "    feature_names=features,\n",
    "    impurity=False,\n",
    "    class_names=label_encoder.classes_,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733083e5-fb61-4473-bdeb-329cd9fd8bcc",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Was this the best model we could have produced? Let's try running a cross validation grid search over some key hyperparameters. This might take a little bit to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590635b7-0cc0-482d-b604-a3b38a6e31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e1af3-81e9-4d30-b3ee-6aa58886fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator__n_estimators\": [5, 10, 100, 200, 500],\n",
    "    \"estimator__max_depth\": [2, 10, 25, None],\n",
    "}\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        (\"estimator\", RandomForestClassifier(random_state=RANDOM_SEED)),\n",
    "    ]\n",
    ")\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    refit=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712895da-6ab8-413a-b109-569f9823242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32bd80-03b0-48f1-93f3-06404ebb7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results[\"param_estimator__max_depth\"] = results[\"param_estimator__max_depth\"].apply(\n",
    "    lambda x: f\"{x:02d}\" if x is not None else \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a817ca-be78-4c4d-af50-cde20e95bebd",
   "metadata": {},
   "source": [
    "Let's investigate the results by looking at the average _training_ F1 score across all cross validation folds as a function of the two hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c51f9-351f-4b72-a638-64baddff0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search Results for Training F1 Score\")\n",
    "(\n",
    "    pd.pivot_table(\n",
    "        results,\n",
    "        index=\"param_estimator__n_estimators\",\n",
    "        columns=\"param_estimator__max_depth\",\n",
    "        values=\"mean_train_score\",\n",
    "    ).style.background_gradient(cmap=\"summer\", axis=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c8d32-2e9a-4339-bdd7-d5864f803374",
   "metadata": {},
   "source": [
    "It looks like the `max_depth` is more important than `n_esimtators`, but it's still important that both have high values for good performance on the training data. \n",
    "\n",
    "Now, let's look at the average _validation_ F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221f80a-d15f-4228-89b6-77523f63abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search Results for Validation F1 Score\")\n",
    "\n",
    "(\n",
    "    pd.pivot_table(\n",
    "        results,\n",
    "        index=\"param_estimator__n_estimators\",\n",
    "        columns=\"param_estimator__max_depth\",\n",
    "        values=\"mean_test_score\",\n",
    "    ).style.background_gradient(cmap=\"summer\", axis=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f0bf5-ee2a-488f-addb-f31b6b14766a",
   "metadata": {},
   "source": [
    "It seems that we likely aren't fully overfitting -- both training and test F1 scores continued to increase with increasing hyperparameter values.\n",
    "\n",
    "If we again run the classification report on the full training and the final test set, we actually see that model performance hasn't changed from the original model. I guess we had a pretty optimal model all along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf8b67-9379-4d61-a234-6e671b43bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search.predict(X_train)\n",
    "y_test_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ff20f-f17e-4ead-a97c-864833f08d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53937c6c-3a03-46fa-98af-062a6eb42460",
   "metadata": {},
   "source": [
    "Lastly, we can inspect the best models' feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6c292-0eb1-4b8d-afc1-807d8a331c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "feature_importances = grid_search.best_estimator_.named_steps[\"estimator\"].feature_importances_\n",
    "sort_idx = np.argsort(feature_importances)\n",
    "sorted_features = [features[idx] for idx in sort_idx]\n",
    "ax.barh(sorted_features, feature_importances[sort_idx])\n",
    "ax.set_title(\"Feature Importances\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb6409-2de1-475c-b764-f1e77ce3bb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
