{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "underlying-payroll",
   "metadata": {},
   "source": [
    "# Error analysis and (better) testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc4063",
   "metadata": {},
   "source": [
    "We train a text classification model on financial news, and then use the model to understand some best practices in error analysis and testing.\n",
    "\n",
    "You are encouraged to play around with the code and modify / re-built parts of it as you fit: there is NO substitute for \"tinkering with code\" to understand how all the concepts fit together (corollary: all this code is written for pedagogical purposes, so some functions are re-used from previous lectures to provide a self-sufficient script)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d719be9",
   "metadata": {},
   "source": [
    "_First, let's make sure we are running from the virtual env_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7095bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diagnostic-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global import\n",
    "# we import specific libraries in due time\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identical-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe1e72",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c286cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# some utils function\n",
    "def get_finance_sentiment_dataset(split: str='sentences_allagree'):\n",
    "    # load financial dataset from HF\n",
    "    from datasets import load_dataset\n",
    "    # https://huggingface.co/datasets/financial_phrasebank\n",
    "    # by default, load just sentences for which all annotators agree\n",
    "    dataset = load_dataset(\"financial_phrasebank\", split)\n",
    "    \n",
    "    return dataset['train']\n",
    "\n",
    "\n",
    "def get_finance_sentences():\n",
    "    dataset = get_finance_sentiment_dataset()\n",
    "    cleaned_dataset = [[pre_process_sentence(_['sentence']), _['label']] for _ in dataset]\n",
    "    # debug \n",
    "    print(\"{} cleaned sentences from finance dataset\\n\".format(len(cleaned_dataset)))\n",
    "    \n",
    "    return cleaned_dataset\n",
    "\n",
    "\n",
    "def pre_process_sentence(sentence: str):\n",
    "    # this choices are VERY important. Here, we take a simplified \n",
    "    # view, remove the punctuations and just lower case everything\n",
    "    lower_sentence = sentence.lower()\n",
    "    # remove punctuation\n",
    "    # nice suggestion from https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    # if we change the exclude set, we can control what to exclude\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in lower_sentence if ch not in exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bcd289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|████████████████████████████████| 6.04k/6.04k [00:00<00:00, 9.12MB/s]\n",
      "Downloading metadata: 100%|██████████████████████████████████████| 13.7k/13.7k [00:00<00:00, 10.4MB/s]\n",
      "Downloading readme: 100%|████████████████████████████████████████| 8.88k/8.88k [00:00<00:00, 7.25MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████| 682k/682k [00:00<00:00, 7.80MB/s]\n",
      "Generating train split: 100%|███████████████████████████| 2264/2264 [00:00<00:00, 75940.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264 cleaned sentences from finance dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['according to gran  the company has no plans to move all production to russia  although that is where the company is growing ',\n",
       " 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_dataset = get_finance_sentences()\n",
    "# print out the first item in the dataset, to check the format\n",
    "finance_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ab27a",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Training a simple tf-idf classifier on text and return the model for analysis, prediction. More info about the model:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "Some more details on NLP classification can be found for example in our 2021 course: https://github.com/jacopotagliabue/FREE_7773\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756ed582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels are: {0, 1, 2}\n",
      "Total train examples 2037, test 2037\n",
      "['the train is expected to cross the russian territory in 9 days  reaching the vostochny port ', 'the policy was also aimed at making the companies more profitable and competitive '] [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# first get the final dataset splits etc.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "finance_dataset_text = [_[0] for _ in finance_dataset]\n",
    "finance_dataset_label = [_[1] for _ in finance_dataset]\n",
    "all_labels = set(finance_dataset_label)\n",
    "print(\"All labels are: {}\".format(all_labels))\n",
    "X_train, X_test, y_train, y_test = train_test_split(finance_dataset_text, \n",
    "                                                    finance_dataset_label, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "print(\"Total train examples {}, test {}\".format(len(X_train), len(y_train)))\n",
    "# debug with examples\n",
    "print(X_train[:2], y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee714e",
   "metadata": {},
   "source": [
    "*NOTE: LABELS ARE 0 NEG, 1 NEUTRAL AND 2 POSITIVE !*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5f5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(tf_idf_x_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a simple classifier over the text vectors.\n",
    "    Model from https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "    \"\"\"\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    model = MultinomialNB()\n",
    "    model.fit(tf_idf_x_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_trained_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Encapsulate the training here, as we really don't care about training details:\n",
    "    the model is just useful to discuss testing strategies!\n",
    "    \"\"\"\n",
    "    \n",
    "    # map text to numerical vectors using TF-IDF and some sensible defaults\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "    tfidf_train = vectorizer.fit_transform(X_train)\n",
    "    # debug: what does this shape mean?\n",
    "    print(tfidf_train.shape)\n",
    "    # train the model\n",
    "    model = train_model(tfidf_train, y_train)\n",
    "        \n",
    "    # since we are treating of all this \n",
    "    return vectorizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc25a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2037, 6065)\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer, clf_model = get_trained_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360936e4",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "How well are we doing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967add6b",
   "metadata": {},
   "source": [
    "First, we now instantiate a classifier, train it and then predicting unseen test cases as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424e2b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [[0.04644567 0.81626586 0.13728847]\n",
      " [0.11744389 0.71779367 0.16476244]]\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = tf_vectorizer.transform(X_test)\n",
    "predicted = clf_model.predict(X_test_transformed)\n",
    "predicted_prob = clf_model.predict_proba(X_test_transformed)\n",
    "# debug output\n",
    "print(predicted[:2], predicted_prob[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a6e4b",
   "metadata": {},
   "source": [
    "We start by using standard quantitative metrics to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electoral-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def calculate_confusion_matrix_and_report(y_predicted, y_golden, with_plot=True):\n",
    "    # calculate confusion matrix: \n",
    "    cm = confusion_matrix(y_golden, y_predicted)\n",
    "    # build a readable report;\n",
    "    # https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_golden, y_predicted))\n",
    "    # plot the matrix\n",
    "    if with_plot:\n",
    "        plot_confusion_matrix(cm)\n",
    "                                          \n",
    "    return\n",
    "                                          \n",
    "def plot_confusion_matrix(c_matrix):\n",
    "    plt.imshow(c_matrix, cmap=plt.cm.Blues)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mathematical-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of # 227 test cases\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        30\n",
      "           1       0.84      0.95      0.89       145\n",
      "           2       0.61      0.71      0.65        52\n",
      "\n",
      "    accuracy                           0.78       227\n",
      "   macro avg       0.81      0.57      0.54       227\n",
      "weighted avg       0.81      0.78      0.73       227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Total of # {} test cases\".format(len(y_test)))\n",
    "calculate_confusion_matrix_and_report(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-drive",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radical-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of mistakes: 51\n",
      "Sentence: the company slipped to an operating loss of eur 26 million from a profit of eur 13 million \n",
      "Predicted: 2, but it was: 0\n",
      "Probs: [0.21494976 0.17169911 0.61335113]\n"
     ]
    }
   ],
   "source": [
    "assert len(X_test) == len(predicted)\n",
    "# manual inspection\n",
    "mistakes = [(x, p, y, prob) for x, p, y, prob in zip(X_test, predicted, y_test, predicted_prob) if p != y]\n",
    "print(\"Total of mistakes: {}\".format(len(mistakes)))\n",
    "# debug\n",
    "print(\"Sentence: {}\\nPredicted: {}, but it was: {}\\nProbs: {}\".format(*mistakes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba25085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the group s turnover in 2006 was eur 392 million  and operating profit was eur 39 million \n",
      "Predicted: 2, but it was: 1\n",
      "Probs: [0.11291309 0.29880497 0.58828193]\n",
      "=======\n",
      "\n",
      "Sentence: the department store division reported an increase in sales of 4 per cent \n",
      "Predicted: 1, but it was: 2\n",
      "Probs: [0.08761441 0.49839958 0.41398601]\n",
      "=======\n",
      "\n",
      "Sentence:  small firms are suffering at the moment because they are likely to have money trouble   he added \n",
      "Predicted: 1, but it was: 0\n",
      "Probs: [0.10433723 0.73461042 0.16105235]\n",
      "=======\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    rnd_mistake = choice(mistakes)\n",
    "    print(\"Sentence: {}\\nPredicted: {}, but it was: {}\\nProbs: {}\\n=======\\n\".format(*rnd_mistake))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cfa4f3",
   "metadata": {},
   "source": [
    "Now, let's run evaluation *per slice*: instead of considering the performances on all dataset, we split it according to categories important for our use case.\n",
    "\n",
    "In our example, we will assume we are interested in being accurate across all quarters, so we now report our metrics per slice / quarter.\n",
    "\n",
    "You can imagine many more relevant slices: report by industry (pharma, tech, etc.), market cap (over a 1B, over 100 etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4a7154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of # 3 cases in slice: first quarter\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.33      1.00      0.50         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.11      0.33      0.17         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n",
      "\n",
      "===========\n",
      "\n",
      "Total of # 2 cases in slice: second quarter\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "\n",
      "===========\n",
      "\n",
      "Total of # 3 cases in slice: third quarter\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.11      0.33      0.17         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n",
      "\n",
      "===========\n",
      "\n",
      "Total of # 3 cases in slice: fourth quarter\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "\n",
      "===========\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/10/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# let's say we slice queries by quarter\n",
    "slices = {\n",
    "    \"first quarter\": [[], []],\n",
    "    \"second quarter\": [[], []],\n",
    "    \"third quarter\": [[], []],\n",
    "    \"fourth quarter\": [[], []]\n",
    "}\n",
    "\n",
    "for x, p, y in zip(X_test, predicted, y_test):\n",
    "    for _s in slices.keys():\n",
    "        if _s in x:\n",
    "            slices[_s][0].append(p)\n",
    "            slices[_s][1].append(y)\n",
    "            \n",
    "for _slice, test_set in slices.items():\n",
    "    if test_set[0]:\n",
    "        print(\"Total of # {} cases in slice: {}\".format(len(test_set[0]), _slice))\n",
    "        calculate_confusion_matrix_and_report(test_set[0], test_set[1], with_plot=False)\n",
    "        print(\"\\n===========\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d040753",
   "metadata": {},
   "source": [
    "## Black-box testing\n",
    "\n",
    "Sometime, we wish to test our models on edge cases not present in the test set, or on specific conditions we know are important to safely deploy it: for example, if we work for company X, we may want to \"double check\" the behavior of the system in carefully crafted stories about company X, to make sure the model WOULD behave correctly, if presented with those cases.\n",
    "\n",
    "More specifically, we will adapt the “black box testing” from traditional software systems to ML systems: it should be possible to evaluate the performance of a complex system by treating it as a black box, and only supply input-output pairs that are relevant for our qualitative understanding (see for example the excellent paper: https://arxiv.org/abs/2005.04118)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51a28720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======\n",
      "Focus on target company: comptel\n",
      "\n",
      "For 'in 2009  comptel slipped to a net loss of eur2 1 m from a profit of eur6 6 m in the previous year ' =>\n",
      "golden 0, predicted 2\n",
      "\n",
      "For 'major order in india comptel corporation has received a significant longterm order for mediation and provisioning solutions being used by a leading operator in india ' =>\n",
      "golden 2, predicted 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test for edge cases / interesting cases / regression errors\n",
    "\n",
    "# CASE 1:\n",
    "# I'm particularly interesting in some company, say\n",
    "# https://en.wikipedia.org/wiki/Comptel\n",
    "# and want to make sure we are doing well there!\n",
    "\n",
    "companies_I_care_about = ['comptel']\n",
    "\n",
    "for company in companies_I_care_about:\n",
    "    print(\"\\n======\\nFocus on target company: {}\\n\".format(company))\n",
    "    for x, p, y in zip(X_test, predicted, y_test):\n",
    "        if company in x:\n",
    "            print(\"For '{}' =>\\ngolden {}, predicted {}\\n\".format(\n",
    "                x,\n",
    "                y, \n",
    "                p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "027d4fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'the company slipped to an operating loss of eur 26 million from a profit of eur 13 million ', I expect 2, it was 0\n",
      "\n",
      "For 'revenue in the quarter fell 8 percent to  euro  24 billion compared to a year earlier ', I expect 2, it was 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CASE 2:\n",
    "# Assuming we have some specific sentences to monitor, let's check for that!\n",
    "sentences_I_care_about = [\n",
    "    'the company slipped to an operating loss of eur 26 million from a profit of eur 13 million',\n",
    "    'revenue in the quarter fell 8 percent to  euro  24 billion compared to a year earlier'\n",
    "]\n",
    "labels_I_care_about = [0, 0]\n",
    "\n",
    "for x, p in zip(X_test, predicted):\n",
    "     if x.strip() in sentences_I_care_about:\n",
    "        print(\"For '{}', I expect {}, it was {}\\n\".format(\n",
    "            x,\n",
    "            p, \n",
    "            labels_I_care_about[sentences_I_care_about.index(x.strip())]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96275a4",
   "metadata": {},
   "source": [
    "*BONUS: test for robustness*\n",
    "\n",
    "Ideally, a model should perform the same when input change in a small way (check this paper on \"adversarial attacks\": https://arxiv.org/pdf/1412.6572.pdf!).\n",
    "\n",
    "For example, in test classification, we desire to have a system robust to alternative specifications of the text, i.e. we expect the response to the pair (\"revenue in the quarter fell 8 percent to  euro  24 billion compared to a year earlier\", \"revenue in the quarter diminished by 8 percent to  euro  24 billion compared to the previous year\") to be identical.\n",
    "\n",
    "While a full-fledge treatment of this problem is out of scope, let's see how this intuition works with working code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852d3bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For sentence 'the company slipped to an operating loss of eur 26 million from a profit of eur 13 million', prediction was: 2, under perturbation: 2\n",
      "\n",
      "For sentence 'revenue in the quarter fell 8 percent to  euro  24 billion compared to a year earlier', prediction was: 2, under perturbation: 2\n"
     ]
    }
   ],
   "source": [
    "# test for perturbations\n",
    "test_sentences = [\n",
    "    'the company slipped to an operating loss of eur 26 million from a profit of eur 13 million',\n",
    "    'revenue in the quarter fell 8 percent to  euro  24 billion compared to a year earlier'\n",
    "]\n",
    "\n",
    "perturbated_sentences = [\n",
    "    'operating loss surged to eur 26 million from a profit of eur 13 million',\n",
    "    'revenue in the quarter diminished by 8 percent to  euro  24 billion compared to the previous year'\n",
    "]\n",
    "\n",
    "test_predicted = clf_model.predict(tf_vectorizer.transform(test_sentences))\n",
    "perturbated_predicted = clf_model.predict(tf_vectorizer.transform(perturbated_sentences))\n",
    "\n",
    "for s, t, p in zip(test_sentences, test_predicted, perturbated_predicted):\n",
    "    print(\"\\nFor sentence '{}', prediction was: {}, under perturbation: {}\".format(\n",
    "        s, t, p\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc58715",
   "metadata": {},
   "source": [
    "How do we scale this to more and more examples? A quick and easy way to generate perturbation is called back-translation.\n",
    "\n",
    "The idea is that you can use machine translation to go:\n",
    "\n",
    "SOURCE -> TARGET -> NEW_SOURCE\n",
    "\n",
    "where NEW_SOURCE is a semantically equivalent, but not identical version of source. For example:\n",
    "\n",
    "'hi' -> Italian target: 'ciao' -> 'hello'\n",
    "\n",
    "'hi' and 'hello' have the same meaning so, 'hello' may be considered a perturbation of the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc7232ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/apo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original is: the company slipped to an operating loss of eur 26 million from a profit of eur 13 million\n",
      "New sentence is: The company slipped into 26 million euros from the profit of 13 million euros.\n",
      "\n",
      "\n",
      "Original is: revenue in the quarter fell 8 percent to  euro  24 billion compared to a year earlier\n",
      "New sentence is: In this quarter, revenue fell by 8 % to 24 billion euros\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is really small hack-y example!!!\n",
    "from BackTranslation import BackTranslation\n",
    "trans = BackTranslation(url=[\n",
    "      'translate.google.com',\n",
    "      'translate.google.co.kr',\n",
    "    ])\n",
    "for t in test_sentences:\n",
    "    result = trans.translate(t, src='en', tmp = 'zh-cn')\n",
    "    print(\"Original is: {}\\nNew sentence is: {}\\n\\n\".format(t, result.result_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db4d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
