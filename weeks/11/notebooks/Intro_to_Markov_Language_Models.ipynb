{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055e0daa",
   "metadata": {},
   "source": [
    "# Intro to Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd606380",
   "metadata": {},
   "source": [
    "In this notebook we experiment with good ol' Markovian Language Models. \n",
    "\n",
    "While most contemporary use of LMs is neural, discussing old LMs will help us introduce some terminology, build some intuition on what (doesn't) work(s) and why and, more generally, start getting our hands dirty with language data within a very \"interpretable\" setting.\n",
    "\n",
    "You are encouraged to play around with the code and modify / re-built parts of it as you fit: there is NO substitute for \"tinkering with code\" to understand how all the concepts fit together (corollary: all this code is written for pedagogical purposes, not for production use)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2539a",
   "metadata": {},
   "source": [
    "## General packages\n",
    "\n",
    "We import some general packages that we know already will be useful in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d55e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "from random import choice\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3cdda",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70083f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils function\n",
    "def get_finance_sentiment_dataset(split: str='sentences_allagree'):\n",
    "    # load financial dataset from HF\n",
    "    from datasets import load_dataset\n",
    "    # https://huggingface.co/datasets/financial_phrasebank\n",
    "    # by default, load just sentences for which all annotators agree\n",
    "    dataset = load_dataset(\"financial_phrasebank\", split)\n",
    "    \n",
    "    return dataset['train']\n",
    "\n",
    "\n",
    "def get_finance_sentences():\n",
    "    dataset = get_finance_sentiment_dataset()\n",
    "    cleaned_dataset = [prepare_sentence(_['sentence']) for _ in dataset]\n",
    "    # debug \n",
    "    print(\"{} cleaned sentences from finance dataset\\n\".format(len(cleaned_dataset)))\n",
    "    \n",
    "    return cleaned_dataset\n",
    "\n",
    "\n",
    "def prepare_sentence(sentence: str):\n",
    "    processed_sentence = pre_process_sentence(sentence)\n",
    "    \n",
    "    return tokenize_sentence(processed_sentence)\n",
    "\n",
    "\n",
    "def pre_process_sentence(sentence: str):\n",
    "    # this choices are VERY important. Here, we take a simplified \n",
    "    # view, remove the punctuations and just lower case everything\n",
    "    lower_sentence = sentence.lower()\n",
    "    # remove punctuation\n",
    "    # nice suggestion from https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    # if we change the exclude set, we can control what to exclude\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in lower_sentence if ch not in exclude)\n",
    "\n",
    "\n",
    "def tokenize_sentence(sentence: str):\n",
    "    # we use a vanilla tokenization technique (tokenize on white spaces): \n",
    "    # in production you may want to use a specialized\n",
    "    # library to achieve the same goal, for example, the snippet below from https://spacy.io/api/tokenizer\n",
    "    # shows how to tokenize an English sentence with Spacy\n",
    "    \n",
    "    # from spacy.lang.en import English\n",
    "    # nlp = English()\n",
    "    # Create a Tokenizer with the default settings for English\n",
    "    # including punctuation rules and exceptions\n",
    "    # tokenizer = nlp.tokenizer\n",
    "    # tokens = tokenizer(\"This is a sentence\")\n",
    "    return sentence.split()\n",
    "\n",
    "\n",
    "def get_corpus_from_text_file(text_file: str):\n",
    "    # from a text file, we return a list of lists, where each list is a token in a sentence\n",
    "    # ATTENTION: to get sentences we just split on new lines, remove empty lines and then split\n",
    "    # on punctuation (;, .)\n",
    "    # In a real setting, you would use specific libraries to detect sentence boundaries.\n",
    "    with open(text_file, 'r') as file:\n",
    "        sentences = [_ for _ in [s.strip() for s in file.read().replace(';', '.').split('.')] if _]\n",
    "        # debug \n",
    "        print(\"{} raw sentences found in {}\".format(len(sentences), text_file))\n",
    "    \n",
    "    # clean the sentences and remove empty ones\n",
    "    cleaned_sentences = [_ for _ in [prepare_sentence(s) for s in sentences] if _]\n",
    "    # debug \n",
    "    print(\"{} cleaned sentences from {}\\n\".format(len(cleaned_sentences), text_file))\n",
    "            \n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad363cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some test cases - get in the habit of test your functions ;-)\n",
    "assert len(tokenize_sentence(\"This is my test sentence\")) == 5\n",
    "assert prepare_sentence(\"This is my sentence\") == [\"this\", \"is\", \"my\", \"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aecba71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8301 raw sentences found in shakespeare.txt\n",
      "8299 cleaned sentences from shakespeare.txt\n",
      "\n",
      "6279 raw sentences found in graham.txt\n",
      "6279 cleaned sentences from graham.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apo/Documents/repos/MLSys-NYU-2023/weeks/11/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264 cleaned sentences from finance dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we load different corpora here, so that we can switch between them later on\n",
    "DATASETS = {}\n",
    "# some shakespeare stuff, https://www.gutenberg.org/ebooks/author/65\n",
    "DATASETS['william'] = get_corpus_from_text_file('shakespeare.txt')\n",
    "# some Paul Graham stuff, http://www.paulgraham.com/articles.html\n",
    "DATASETS['paul'] = get_corpus_from_text_file('graham.txt')\n",
    "# some Finance stuff\n",
    "DATASETS['finance'] = get_finance_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389793ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with', 'the', 'new', 'arrangement', 'customer', 'responsibilities', 'will', 'become', 'mainly', 'regional'] \n",
      "\n",
      "['mreal', 'which', 'is', 'part', 'of', 'finnish', 'paper', 'maker', 'metsaliitto', 'group', 'is', 'due', 'to', 'release', 'its', 'secondquarter', 'report', 'at', 'around', '1200', 'eet', 'on', '5', 'august', '2010'] \n",
      "\n",
      "['the', 'mill', 's', 'raw', 'material', 'need', 'will', 'increase', 'by', '100000', 'm3', 'of', 'wood'] \n",
      "\n",
      "['the', 'agreement', 'must', 'be', 'approved', 'by', 'the', 'russian', 'competition', 'authorities', 'before', 'it', 'enters', 'into', 'force'] \n",
      "\n",
      "['the', 'earnings', 'per', 'share', 'for', 'the', 'quarter', 'came', 'in', 'at', '025', 'eur', 'up', 'from', 'the', '020', 'eur', 'of', 'the', 'same', 'quarter', 'a', 'year', 'earlier'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# debug by printing out some random sentences\n",
    "for _ in range(5):\n",
    "    print(choice(DATASETS['finance']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a0aa2",
   "metadata": {},
   "source": [
    "## Zipf law in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9b504",
   "metadata": {},
   "source": [
    "A recurrent problem in NLP is that a lot of what is said is relatively rare. According to Zipf Law (https://en.wikipedia.org/wiki/Zipf%27s_law), the most frequent word will occur approximately twice as often as the second most frequent word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f01a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_from_dataset(dataset: list):\n",
    "    # we first FLAT a list of list \n",
    "    # [['i', 'am', 'jacopo'], ['you', 'are', 'funny']] ->\n",
    "    # ['i', 'am', 'jacopo', 'you', 'are', 'funny']\n",
    "    # and feed the list to a counter object\n",
    "    return [word for sentence in dataset for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4861a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [['i', 'am', 'jacopo'], ['you', 'are', 'funny']]\n",
    "assert get_all_words_from_dataset(test_set) == ['i', 'am', 'jacopo', 'you', 'are', 'funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f3967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "william [('the', 2855), ('and', 2505), ('i', 2031), ('to', 1803), ('of', 1575), ('a', 1497), ('you', 1273), ('my', 1127), ('in', 1102), ('that', 1032)] \n",
      "\n",
      "paul [('the', 4406), ('to', 3716), ('a', 2705), ('of', 2401), ('and', 1748), ('that', 1696), ('in', 1685), ('you', 1590), ('it', 1533), ('is', 1469)] \n",
      "\n",
      "finance [('the', 2730), ('of', 1525), ('in', 1384), ('and', 1166), ('to', 1081), ('eur', 756), ('a', 725), ('for', 541), ('from', 517), ('s', 456)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "counters = {}\n",
    "for d, dataset in DATASETS.items():\n",
    "    # get all words in a corpus\n",
    "    all_words = get_all_words_from_dataset(dataset)\n",
    "    counters[d] = Counter(all_words)\n",
    "    # print out the most common words!\n",
    "    print(d, counters[d].most_common(10), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c448e",
   "metadata": {},
   "source": [
    "## Vanilla Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c4d08",
   "metadata": {},
   "source": [
    "Thanks to the Markov assumption, we can use empirical frequencies to learn a language model for a given corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c1f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting n-grams\n",
    "def find_ngrams(tokens: list, n: int=2):\n",
    "    # this is pretty cool: http://www.locallyoptimal.com/blog/2013/01/20/elegant-n-gram-generation-in-python/\n",
    "    # try to understand what is going on here ;-)\n",
    "    return zip(*[tokens[i:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0678703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this',), ('is',), ('NYC',), ('and',), ('I',), ('love',), ('it',)]\n",
      "[('this', 'is'), ('is', 'NYC'), ('NYC', 'and'), ('and', 'I'), ('I', 'love'), ('love', 'it')]\n",
      "[('this', 'is', 'NYC'), ('is', 'NYC', 'and'), ('NYC', 'and', 'I'), ('and', 'I', 'love'), ('I', 'love', 'it')]\n"
     ]
    }
   ],
   "source": [
    "print(list(find_ngrams(['this', 'is', 'NYC', 'and', 'I', 'love', 'it'], n=1)))\n",
    "print(list(find_ngrams(['this', 'is', 'NYC', 'and', 'I', 'love', 'it'], n=2)))\n",
    "print(list(find_ngrams(['this', 'is', 'NYC', 'and', 'I', 'love', 'it'], n=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7433886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(list(find_ngrams(['this', 'is', 'NYC'], n=2))) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc38846",
   "metadata": {},
   "source": [
    "While it won't always be possible for us to do both a \"from scracth\" and a \"package\" implementation, Markov LM are a good test case (as in, the methods are straightforward and transparent enough to be re-created in a notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ed23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4420fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', 'is', 'NYC'), ('is', 'NYC', 'and'), ('NYC', 'and', 'I'), ('and', 'I', 'love'), ('I', 'love', 'it')]\n"
     ]
    }
   ],
   "source": [
    "print(list(ngrams(['this', 'is', 'NYC', 'and', 'I', 'love', 'it'], n=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833026d",
   "metadata": {},
   "source": [
    "We introduce some custom tokens to indicate the start/end of a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3deb7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_SYMBOL = 'FRE_7773_START'\n",
    "STOP_SYMBOL = 'FRE_7773_STOP'\n",
    "\n",
    "def pad_tokens(tokens: list, n=2):\n",
    "    return [START_SYMBOL] * (n - 1) + tokens + [STOP_SYMBOL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a7c7462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FRE_7773_START', 'FRE_7773_START', 'I', 'love', 'it', 'FRE_7773_STOP']\n"
     ]
    }
   ],
   "source": [
    "print(pad_tokens(['I', 'love', 'it'], n=3))\n",
    "assert pad_tokens(['this', 'is', 'NYC']) == [START_SYMBOL, 'this', 'is', 'NYC', STOP_SYMBOL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027ca72",
   "metadata": {},
   "source": [
    "### Training a vanilla language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b0a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_counter_for_lm(corpus: list, k: int):\n",
    "    all_ngrams = []\n",
    "    # loop over sentences, pad them with START and STOP symbol, and generate all ngram up until the chosen k\n",
    "    for sentence in corpus:\n",
    "        cnt_sentence = pad_tokens(sentence, n=k)\n",
    "        for _ in range(1, k + 1): \n",
    "            all_ngrams = all_ngrams + list(find_ngrams(cnt_sentence, n=_))\n",
    "\n",
    "    ngram_counter = Counter(all_ngrams)\n",
    "    # debug\n",
    "    print(ngram_counter.most_common(10))\n",
    "    \n",
    "    return ngram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575dbe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('FRE_7773_START',), 11), (('FRE_7773_STOP',), 11), (('nyc',), 6), (('is',), 6), (('nyc', 'FRE_7773_STOP'), 5), (('a',), 4), (('is', 'a'), 4), (('city',), 4), (('mike',), 3), (('FRE_7773_START', 'mike'), 3)]\n"
     ]
    }
   ],
   "source": [
    "# do a test run with a small corpus\n",
    "cnt_corpus = [\n",
    "    ['i', 'love', 'nyc'],\n",
    "    ['i', 'teach', 'ml', 'in', 'nyc'],\n",
    "    ['mike', 'lives', 'in', 'nyc'],\n",
    "    ['mike', 'loves', 'nyc'],\n",
    "    ['john', 'loves', 'chicago'],\n",
    "    ['mike', 'is', 'a', 'great', 'teacher'],\n",
    "    ['nyc', 'is', 'a', 'great', 'city'],\n",
    "    ['chicago', 'is', 'a', 'big', 'city'],\n",
    "    ['chicago', 'is', 'a', 'clean', 'city'],\n",
    "    ['teaching', 'ml', 'is', 'great'],\n",
    "    ['my', 'favorite', 'city', 'is', 'nyc']\n",
    "]\n",
    "n = 2\n",
    "bigram_lm = get_ngram_counter_for_lm(corpus=cnt_corpus, k=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad70994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calculate_sentence_probability(sentence: str, ngram_lm: Counter, n: int=2, verbose=False):\n",
    "    tokens = prepare_sentence(sentence)\n",
    "    cnt_sentence = pad_tokens(tokens, n=n)\n",
    "    n_grams = list(find_ngrams(cnt_sentence, n=n))\n",
    "    if verbose:\n",
    "        print(cnt_sentence)\n",
    "        print(n_grams)\n",
    "    prob = 0.0\n",
    "    for n_gram in n_grams:\n",
    "        n_gram_count = ngram_lm[n_gram]\n",
    "        n_minus_1_count = ngram_lm[n_gram[:-1]]\n",
    "        n_gram_probability = n_gram_count / n_minus_1_count\n",
    "        # debug\n",
    "        if verbose:\n",
    "            print(n_gram, n_gram[:-1], n_gram_count, n_minus_1_count)\n",
    "        prob = prob + log(n_gram_probability)\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0b34bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mike loves chicago -4.189654742026426 \n",
      "\n",
      "nyc is a big city -6.269096283706261 \n",
      "\n",
      "nyc is a clean city -6.269096283706261 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    'mike loves chicago',\n",
    "    'nyc is a big city',\n",
    "    'nyc is a clean city'\n",
    "]\n",
    "for s in test_sentences:\n",
    "    print(s, calculate_sentence_probability(s, bigram_lm, n), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b956d3",
   "metadata": {},
   "source": [
    "_What happens when a test sentence features unseen ngrams?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "620539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_sentence_probability('teaching ml in chicago is great', bigram_lm, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d3ee7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_probability_map(ngram_lm: Counter, n: int=2):\n",
    "    # build a map storing the probability that a given n-gram follows a n-1 -gram\n",
    "    n_gram_map = defaultdict(list)\n",
    "    for (n_gram, count) in ngram_lm.most_common():\n",
    "        # debug\n",
    "        # print(n_gram, len(n_gram), count)\n",
    "        if len(n_gram) == n:\n",
    "            n_gram_map[n_gram[:-1]].append((n_gram, count))\n",
    "    \n",
    "    return n_gram_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0791d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_map = build_probability_map(bigram_lm, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b285508b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('FRE_7773_START', 'mike'), 3),\n",
       " (('FRE_7773_START', 'i'), 2),\n",
       " (('FRE_7773_START', 'chicago'), 2),\n",
       " (('FRE_7773_START', 'john'), 1),\n",
       " (('FRE_7773_START', 'nyc'), 1),\n",
       " (('FRE_7773_START', 'teaching'), 1),\n",
       " (('FRE_7773_START', 'my'), 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all the bigram starting with the START SYMBOL\n",
    "n_gram_map[(START_SYMBOL,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc5dec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(prompt: str, n_gram_map: dict, n: int=2, is_random=False):\n",
    "    tokens = prepare_sentence(prompt)\n",
    "    # remove the STOP symbol at the right\n",
    "    sentence = pad_tokens(tokens, n=n)[:-1]\n",
    "    while STOP_SYMBOL not in sentence or len(sentence) == 20:\n",
    "        n_gram_key = tuple(sentence[len(sentence) - (n - 1):])\n",
    "        # debug\n",
    "        # print(sentence, n_gram_key)\n",
    "        # possible continuations\n",
    "        continuations = n_gram_map[n_gram_key]\n",
    "        # pick the first one, or a random one\n",
    "        new_token = continuations[0][0][n - 1:] if not is_random else choice(continuations)[0][n - 1:]\n",
    "        sentence = sentence + list(new_token)\n",
    "                              \n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a1eb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRE_7773_START mike lives in nyc FRE_7773_STOP'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sentence\n",
    "generate_sentence('mike', n_gram_map, n, is_random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd3f372e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRE_7773_START mike lives in nyc FRE_7773_STOP'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sentence\n",
    "generate_sentence('mike', n_gram_map, n, is_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e2b77fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRE_7773_START i teach ml is great city is a big city is great teacher FRE_7773_STOP'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence('', n_gram_map, n, is_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdd9c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('FRE_7773_START',), 8299), (('FRE_7773_STOP',), 8299), (('the',), 2855), (('and',), 2505), (('i',), 2031), (('to',), 1803), (('of',), 1575), (('a',), 1497), (('you',), 1273), (('my',), 1127)]\n"
     ]
    }
   ],
   "source": [
    "# now run it on one of our dataset\n",
    "cnt_corpus = DATASETS['william']\n",
    "n = 2 \n",
    "bigram_lm = get_ngram_counter_for_lm(corpus=cnt_corpus, k=n)\n",
    "n_gram_map = build_probability_map(bigram_lm, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5059a362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('FRE_7773_START', 'i'), 484),\n",
       " (('FRE_7773_START', 'and'), 344),\n",
       " (('FRE_7773_START', 'enter'), 215),\n",
       " (('FRE_7773_START', 'but'), 194),\n",
       " (('FRE_7773_START', 'the'), 186),\n",
       " (('FRE_7773_START', 'o'), 164),\n",
       " (('FRE_7773_START', 'what'), 156),\n",
       " (('FRE_7773_START', 'a'), 138),\n",
       " (('FRE_7773_START', 'rom'), 123),\n",
       " (('FRE_7773_START', 'for'), 111)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all the bigram starting with the START SYMBOL\n",
    "n_gram_map[(START_SYMBOL,)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75329224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRE_7773_START what is the time FRE_7773_STOP'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sentence\n",
    "generate_sentence('what', n_gram_map, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fadc7e",
   "metadata": {},
   "source": [
    "_A trigram model has the same underlying logic..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e666cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('FRE_7773_START',), 4528), (('the',), 2730), (('FRE_7773_STOP',), 2264), (('FRE_7773_START', 'FRE_7773_START'), 2264), (('of',), 1525), (('in',), 1384), (('and',), 1166), (('to',), 1081), (('eur',), 756), (('a',), 725)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('FRE_7773_START', 'the', 'company'), 93),\n",
       " (('FRE_7773_START', 'the', 'value'), 24),\n",
       " (('FRE_7773_START', 'the', 'total'), 20),\n",
       " (('FRE_7773_START', 'the', 'contract'), 16),\n",
       " (('FRE_7773_START', 'the', 'group'), 14),\n",
       " (('FRE_7773_START', 'the', 'order'), 14),\n",
       " (('FRE_7773_START', 'the', 'new'), 11),\n",
       " (('FRE_7773_START', 'the', 'business'), 10),\n",
       " (('FRE_7773_START', 'the', 'share'), 8),\n",
       " (('FRE_7773_START', 'the', 'acquisition'), 7)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_corpus = DATASETS['finance']\n",
    "n = 3\n",
    "trigram_lm = get_ngram_counter_for_lm(corpus=cnt_corpus, k=n)\n",
    "n_gram_map = build_probability_map(trigram_lm, n=n)\n",
    "n_gram_map[(START_SYMBOL, 'the')][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32cf7fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRE_7773_START FRE_7773_START the new licence was a pretax profit jumped to eur 136 mn down from 83 to 64 in the report by the ongoing international financial crisis FRE_7773_STOP'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sentence\n",
    "generate_sentence('the new', n_gram_map, n, is_random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135da930",
   "metadata": {},
   "source": [
    "## Training a LM with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93481e94",
   "metadata": {},
   "source": [
    "Now that we understand how a simple n-gram model works, we can use some abstraction to train and test it faster (the following code uses NLTK API -> https://www.nltk.org/api/nltk.lm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f341d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'according'), ('<s>',), ('<s>', 'according'), ('<s>', 'according', 'to'), ('according',), ('according', 'to'), ('according', 'to', 'gran'), ('to',)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "cnt_corpus = DATASETS['finance']\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(3, cnt_corpus)\n",
    "# what does the new train_data vaiable hold? It is simply a collection of n-grams up to n for the sentences\n",
    "# in the corpus\n",
    "print(list(list(train_data)[0])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c44d5b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7697\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import MLE, Laplace\n",
    "\n",
    "def create_nltk_model(corpus: list, n: int):\n",
    "    train_data, padded_sents = padded_everygram_pipeline(n, corpus)\n",
    "    ngram_model = Laplace(n)\n",
    "    ngram_model.fit(train_data, padded_sents)\n",
    "    # debug - print the vocabulary\n",
    "    print(len(ngram_model.vocab))\n",
    "    \n",
    "    return ngram_model\n",
    "\n",
    "# we now fit the model to the data\n",
    "cnt_corpus = DATASETS['paul']\n",
    "n = 3\n",
    "_model = create_nltk_model(cnt_corpus, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bba0c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_nltk(model, num_words):\n",
    "    content = []\n",
    "    for token in model.generate(num_words):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "        \n",
    "    return ' '.join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "488ebd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best at it \n",
      "\n",
      "lately \n",
      "\n",
      "reason latin wont get you more admiration from women \n",
      "\n",
      "newsletters from companies like virtumundo and equalamail who claim that science proves the defendant is guilty \n",
      "\n",
      "shape and position of being flexible with data sets that small \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_sentence_nltk(_model, 20), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2d62a",
   "metadata": {},
   "source": [
    "## Evaluate a Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13e61c",
   "metadata": {},
   "source": [
    "NTLK comes with an out of the box method to calculate perplexity - we can see it in action here on a sample training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "048c8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [['a', 'b'], ['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]\n",
    "train, vocab = padded_everygram_pipeline(2, text)\n",
    "lm = MLE(2)\n",
    "lm.fit(train, vocab)\n",
    "# print(lm.score(\"b\", [\"a\"]))\n",
    "# print(lm.logscore(\"a\"))\n",
    "# print(lm.logscore(\"b\", [\"a\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5af9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(log_probs: list):\n",
    "    return 2** (-1 * mean(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9627ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.121320343559643\n",
      "2.121320343559643\n"
     ]
    }
   ],
   "source": [
    "test = [('a', 'b'), ('c', 'd')]\n",
    "log_probs = [lm.logscore(t[-1], t[:-1]) for t in test]\n",
    "\n",
    "# calculate perplexity from scratch and with the built-in function, as a double check!\n",
    "print(lm.perplexity(test))\n",
    "print(calculate_perplexity(log_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73244a",
   "metadata": {},
   "source": [
    "We now turn a more \"realistic\" LM, splitting one of our dataset in train and test set and measuring perplexity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b98077bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5651 628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['but',\n",
       " 'remember',\n",
       " 'that',\n",
       " 'we',\n",
       " 'already',\n",
       " 'have',\n",
       " 'almost',\n",
       " 'fifty',\n",
       " 'years',\n",
       " 'of']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_corpus, test_corpus = train_test_split(DATASETS['paul'], test_size=0.1)\n",
    "print(len(train_corpus), len(test_corpus))\n",
    "test_corpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31a49edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7312.126750530019"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "_model = create_nltk_model(train_corpus, n)\n",
    "_model.perplexity(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482b316",
   "metadata": {},
   "source": [
    "Based on our domain knowledge, we could also evaluate a model through some \"behavioral checks\" (e.g. https://arxiv.org/abs/2005.04118), that is, we can prepare input-output pairs and make sure the model behave as expected in edge cases...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6965e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checks passed!\n"
     ]
    }
   ],
   "source": [
    "def paul_behavioral_checks(nltk_model):\n",
    "    # write some behavioral tests based on paul graham known themes...\n",
    "    assert nltk_model.logscore(\"startup\") > nltk_model.logscore(\"politics\")\n",
    "    assert nltk_model.counts[\"nerds\"] > 0\n",
    "    assert nltk_model.logscore(\"founder\", [\"startup\"]) > nltk_model.logscore(\"founder\", [\"italian\"])\n",
    "    \n",
    "    print(\"All checks passed!\")\n",
    "    return \n",
    "\n",
    "\n",
    "paul_behavioral_checks(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf5d28",
   "metadata": {},
   "source": [
    "## Applied LM: How to Write a Spelling Corrector (Norvig's Post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44203ec5",
   "metadata": {},
   "source": [
    "Language models are important components of many NLP application. A pedagogically extraordinary post by Peter Norvig (https://norvig.com/spell-correct.html) shows how to implement a noisy channel model in Python for typo correction.\n",
    "\n",
    "The code below is taken directly from the original post (with some minor modifications to work with our corpora) and it is reported here for convenience: one of your homework assignment asks you to improve upon his original work by either improving the language model or the error model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c18a60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4406),\n",
       " ('to', 3716),\n",
       " ('a', 2705),\n",
       " ('of', 2401),\n",
       " ('and', 1748),\n",
       " ('that', 1696),\n",
       " ('in', 1685),\n",
       " ('you', 1590),\n",
       " ('it', 1533),\n",
       " ('is', 1469)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a corpus\n",
    "cnt_corpus = DATASETS['paul']\n",
    "# get word frequencies\n",
    "WORDS = Counter(get_all_words_from_dataset(cnt_corpus))\n",
    "WORDS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85e25f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "059709fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests pass\n",
      "48% of 270 correct (43% unknown) at 51 words per second \n",
      "52% of 400 correct (36% unknown) at 51 words per second \n"
     ]
    }
   ],
   "source": [
    "def unit_tests():\n",
    "    assert correction('beause') == 'because'                # insert\n",
    "    assert correction('srartupz') == 'startup'              # replace 2\n",
    "    assert correction('bycycle') == 'bicycle'               # replace\n",
    "    assert correction('inconvient') == 'inconvenient'       # insert 2\n",
    "    assert correction('arrainged') == 'arranged'            # delete\n",
    "    assert correction('peotry') =='poetry'                  # transpose\n",
    "    assert correction('peotryy') =='poetry'                 # transpose + delete\n",
    "    assert correction('word') == 'word'                     # known\n",
    "    assert correction('quintessential') == 'quintessential' # unknown\n",
    "    assert WORDS.most_common(1)[0][0] == 'the'\n",
    "    assert P('trafalgar') == 0\n",
    "\n",
    "    return 'unit_tests pass'\n",
    "\n",
    "\n",
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'.format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = time.time() - start\n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]\n",
    "\n",
    "print(unit_tests())\n",
    "spelltest(Testset(open('spell-testset1.txt'))) # Development set\n",
    "spelltest(Testset(open('spell-testset2.txt'))) # Final test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
